---
title: "<CENTER>Práctica 5: Procesos ARIMA con estacionalidad</CENTER>"
author: "<CENTER>Zuri Montalar Mendoza<CENTER>"
date: "<CENTER>25/03/2020</CENTER>"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r global_options, include=FALSE,fig.align="center"}
 knitr::opts_chunk$set(warning=FALSE)
```

<div style="text-align: justify">


```{r message=FALSE, echo=FALSE}
setwd("~/BIOESTADÍSTICA máster/Modelización estadística/Series temporales/Practicas/practica5-st")
library(forecast)
library(ggplot2)
library(aod)
library(tseries)
```

Primero leemos el fichero e indicamos que se trata de una serie temporal mensual que va desde enero de 1980 hasta diciembre de 2017. Los datos corresponden al número de defunciones mensuales debidas a enfermedades infecciosas y parasitarias en España. Ya vimos en la práctica 1 que había un cambio importante en el comportamiento de la serie alrededor de 1997 debido a un cambio en la definición de este tipo de enfermedades, por lo que decidimos cortar la serie y consideramos entonces que empieza en 1998. A continuación visualizamos la serie de la que partimos entonces.

```{r cargo datos,message=FALSE, fig.width=13,fig.height=6}
enf<-read.table('Enfermedades_infecciosas_y_parasitarias.txt',header=TRUE) 
enf<-ts(enf,start = c(1980,1), freq = 12)
enf<-window(enf,start=c(1998,1))
plot(enf, xlab="Periodo",ylab="Nº de fallecidos",
     main="Nº fallecidos debido a enfermedades infecciosas y parasitarias")
```

El objetivo de esta práctica es ajustar esa serie temporal con un modelo ARIMA para a continuación realizar predicciones. Compararemos los resultados y errores de este método con los del método de alisado que obtuvimos en la práctica 2. Para ello, hay que tener en cuenta que al ser una serie mensual, tenemos estacionalidad y es de orden 12; y que la serie sobre la que trabajemos ha de ser estacionaria y ergódica, para lo cual en la práctica 3 vimos que la transformación que debíamos aplicar a la serie era una diferenciación regular, otra estacional, y el logaritmo. 


## Identificación del modelo ARIMA

La mayoría de series con estacionalidad se ajustan a una combinación de procesos regulares y estacionales, de la forma $ARIMA_{m}(p,d,q)(P,D,Q)$, siendo *m* el orden estacional. Procedemos a identificar el modelo de dos formas diferentes, para estudiar cuál sería la mejor opción en nuestro caso: observando las funciones de autocorrelación y autocorrelación parcial, y utilizando la función `auto.arima`.


#### Observando ACF y PACF \newline

Para obtener *p*, *q*, *P* y *Q* podemos observar las funciones de autocorrelación (ACF) y autocorrelación parcial (PACF) de la serie transformada:

```{r dsv,fig.align="center", fig.width=13,fig.height=7}
ggtsdisplay(diff(diff(log(enf),lag=12)),lag=48)

```

En el gráfico superior vemos la serie con la transformación $\Delta\Delta_{12}log(y_t)$.

Por un lado, si nos fijamos en la parte regular (es decir, en los primeros valores de retardo), en la gráfica de ACF vemos que se produce un pico (un valor más elevado en valor absoluto de la autocorrelación) en $\rho=1$, y que para el resto de valores de retardo la autocorrelación está dentro de las bandas de confianza al 95%; sin embargo, la gráfica de PACF no es tan esclarecedora. Podríamos considerar que en esta última, también en la parte regular, se produce un decrecimiento de la autocorrelación. En este caso, los valores de *p* y *q* serían entonces 0 y 1 respectivamente.

Por otro lado, si nos fijamos en la parte estacional (es decir, en los valores de retardo múltiplos de 12), en la gráfica de ACF vemos que se produce un pico en $\rho=12$, y que para el resto de valores de retardo ($\rho=24$, $\rho=36$, $\rho=48$) la autocorrelación está dentro de las bandas de confianza al 95%; sin embargo, la gráfica de PACF también resulta en este caso menos esclarecedora. Tal vez podríamos considerar que se produce decrecimiento pues en $\rho=24$ y en $\rho=26$ la autocorrelación no está dentro de la banda de confianza (aunque sí muy próxima a esta), y pese a que el valor en $\rho=26$ es un poco mayor que el de $\rho=24$. De suponerlo así, tendríamos que los valores de *P* y *Q* serían de 0 y 1, respectivamente.

Con ello, tenemos entonces que viendo las gráficas anteriores el modelo podría ser el siguiente: $log(y_t)$**~**$ARIMA_{12}(0,1,1)(0,1,1)$.

#### Utilizando la función `auto.arima` \newline

También podemos ver qué opción de porceso ARIMA nos indica como más adecuada (menor Akaike) la función `auto.arima` del paquete *forecast*.

Como la transformación consistía en una diferenciación regular y una estacional, $d=D=1$. Además, como también aplicábamos el logaritmo, definimos $\lambda=0$.

Por otro lado, en la práctica 2 vimos que había dos outliers al estudaiar el error en la serie original, por lo que vamos a incluirlos para obtener una mejor propuesta del modelo ARIMA (más adelante también los incluiremos al estimar el modelo ARIMA como tal): se trata de agosto de 2003 y enero de 2005.
Entonces, creamos para cada uno de ellos una variable ficticia *dummy*, que estará compuesta por 0's excepto la posición a la que le corresponde el mes del valor atípico, que será un 1. Incluimos estas variables en el argumento *xreg*.

Además, también incluiremos otra variable fictica para tener en cuenta los febreros de años bisiestos, pues al tener un día más que el resto de febreros, es normal que haya más fallecimientos por enfermedades (infecciosas y parasitarias, en este caso).

La serie con la que estamos trabajando empieza en 1998, siendo entonces el primer año bisiesto del que tenemos datos el 2000. Como la serie empieza en enero, el primer febrero bisiesto corresponde a nuestro 26º dato. Partimos de esta información para crear la variable *dummy* que indique qué meses corresponden a febreros de años bisiestos.

```{r}
# Creamos las variables dummy
bisiestos<-rep(0,length(enf))
for (i in 0:trunc(length(enf)/48)) bisiestos[26+48*i]<-1
bisiestos<-bisiestos[1:length(enf)]
d0803<-1*(time(enf)==2003+7/12) # agosto de 2003
d0105<-1*(time(enf)==2005) # enero de 2005

# Utilizamos auto.arima
auto.arima(enf,d=1,D=1,lambda=0,
           xreg=cbind(bisiestos,d0803,d0105))

```

La función `auto.arima` nos ofrece como mejor opción el proceso $log(y_t)$**~**$ARIMA_{12}(1,1,0)(1,1,0)$.

## Estimación del modelo

A continuación estimamos ambos modelos con la función `Arima` y estudiamos los posibles outliers de los residuos, así como la significativadad de los coeficientes que obtengamos (mediante la prueba de Wald, con la función `wald.test` del paquete *aod*). Consideraremos como outliers los valores cuyo error supere 2.9 desviaciones típicas, y los outliers que encontremos los incluiremos como variables ficticias y volveremos a estimar el modelo; los coeficientes que no sean significativos, no los incluiremos en el modelo. 

Realizaremos este procedimiento tantas veces como sea necesario y partiendo de los dos modelos que hemos comentado en el apartado anterior. Tras obtener los modelos aceptables, estudiaremos su validez y nos quedaremos con el modelo que cumpla todas las validaciones. Si ambos las cumplen todas, nos quedaremos con el que menor error de predicción tenga.

#### Partiendo de ARIMA (0,1,1)(0,1,1) [12]  \newline

<!-- ```{r} -->
<!-- # ARIMA (0,1,1)(0,1,1) [12] -->
<!-- # estimación -->
<!-- ar011<-Arima(enf,order=c(0,1,1), -->
<!--               seasonal=list(order=c(0,1,1),period=12), -->
<!--               lambda=0, -->
<!--               xreg=cbind(bisiestos,d0803,d0105)) -->
<!-- ar011 -->

<!-- # Significatividad -->
<!-- pvalores.ar011<-c() -->
<!-- for (i in 1:length(ar011$coef)) pvalores.ar011[i]<-wald.test(b=coef(ar011),Sigma=vcov(ar011),Terms=i)$result$chi2[3] -->
<!-- pvalores.ar011 -->

<!-- # Outliers -->
<!-- error.011<-residuals(ar011,type="response") # (indicamos type="response" porque trabajamos con el logaritmo) -->
<!-- desv.tip<-sd(error.011) # Desviación típica del error -->
<!-- plot(error.011,main="Error de estimación error.011") -->
<!-- abline(h=c(-3,-2,2,3)*desv.tip,lty=2,lwd=2,col=c("blue","red","red","blue")) -->
<!-- # valores atipicos, por encima de la 2.9 desviaciones típicas: -->
<!-- error.011>2.9*desv.tip -->
<!-- error.011< -2.9*desv.tip -->

<!-- ``` -->

Por un lado, con el proceso $log(y_t)$**~**$ARIMA_{12}(0,1,1)(0,1,1)$, incluyendo como valores atípicos a tener en cuenta los febreros bisiestos, agosto de 2003 y enero de 2005, tenemos que todos los coeficientes son significativos (todos los p-valores inferiores a 0.05), excepto el de la intervención de los febreros bisiestos, por lo que quitamos la variable correspondiente al volver a estimar un segundo modelo. Además, se dan 3 posibles outliers (febrero del 2000, junio de 2003 y febrero del 2009), que incluímos como variables *dummy*.

<!-- ```{r} -->
<!-- # ARIMA (0,1,1)(0,1,1) [12] sin bisiestos con outliers -->

<!-- # dummy's -->
<!-- ii <- order(abs(error.011), decreasing = TRUE) -->
<!-- d0603<-rep(0,length(error.011)) -->
<!-- d0200<-rep(0,length(error.011)) -->
<!-- d0209<-rep(0,length(error.011)) -->
<!-- d0603[ii[1]]<-1 # junio de 2003 -->
<!-- d0209[ii[2]]<-1 # febrero del 2009 -->
<!-- d0200[ii[3]]<-1 # febrero del 2000 -->

<!-- # estimación -->
<!-- ar011.2<- Arima(enf,order=c(0,1,1), -->
<!--               seasonal=list(order=c(0,1,1),period=12), -->
<!--               lambda=0, -->
<!--               xreg=cbind(d0803,d0105,d0200,d0603,d0209)) -->
<!-- ar011.2 -->

<!-- # Significatividad -->
<!-- pvalores.ar011.2<-c() -->
<!-- for (i in 1:length(ar011.2$coef)) pvalores.ar011.2[i]<-wald.test(b = coef(ar011.2), Sigma = vcov(ar011.2), Terms =i)$result$chi2[3] -->
<!-- pvalores.ar011.2 -->

<!-- # Outliers -->
<!-- error.011.2<-residuals(ar011.2,type="response") -->
<!-- desv.tip<-sd(error.011.2) # Desviación típica del error -->
<!-- plot(error.011.2,main="Error de estimación error.011.2") -->
<!-- abline(h=c(-3,-2,2,3)*desv.tip,lty=2,lwd=2,col=c("blue","red","red","blue")) -->
<!-- # valores atipicos, por encima de la 2.9 desviaciones típicas: -->
<!-- error.011.2>2.9*desv.tip -->
<!-- error.011.2< -2.9*desv.tip -->

<!-- ``` -->

Al hecerlo, tenemos que el efecto de febrero de 2000 no es significativo (por lo que no lo tenemos en cuenta en el tercer modelo). El p-valor obtenido al realizar el contraste de la significatividad de febrero del 2009 es de 0.059 y, pese a ser mayor que el nivel de significación que estamos considerando (de 0.05), es bastante cercano al mismo y decidimos tener en cuenta su efecto en el modelo. Además, en este segundo modelo no se produce ningún outlier más (ningún valor de error supera 2.9 desviaciones típicas).

Al estimar un tercer modelo (ar011.3) ya tenemos todos los coeficientes significativos y que no se produce ningún error mayor a 2.9 desviaciones típicas (a excepción de febrero del 2000, que ya hemos visto que no es significativo).

Visualizamos a continuación el modelo estimado, los p-valores de cada uno de sus coeficientes y la gráfica del error del modelo (con bandas azules y rojas a 3 y 2 desviaciones típicas, respectivamente):

```{r poi, fig.width=13,fig.height=5}
# ARIMA (0,1,1)(0,1,1) [12] 

# estimación ar011
ar011<-Arima(enf,order=c(0,1,1),
              seasonal=list(order=c(0,1,1),period=12),
              lambda=0,
              xreg=cbind(bisiestos,d0803,d0105))
# Outliers
error.011<-residuals(ar011,type="response") # (indicamos type="response" porque
# trabajamos con el logaritmo)
desv.tip<-sd(error.011) # Desviación típica del error
# valores atipicos, por encima de la 2.9 desviaciones típicas:
# error.011>2.9*desv.tip
# error.011< -2.9*desv.tip


# dummy's
ii <- order(abs(error.011), decreasing = TRUE)
d0603<-rep(0,length(error.011))
d0209<-rep(0,length(error.011))
d0603[ii[1]]<-1 # junio de 2003
d0209[ii[2]]<-1 # febrero del 2009

# estimación ar011.3
ar011.3<- Arima(enf,order=c(0,1,1),
              seasonal=list(order=c(0,1,1),period=12),
              lambda=0,
              xreg=cbind(d0803,d0105,d0603,d0209))
ar011.3

# Significatividad de cada uno de los coeficientes del modelo
pvalores.ar011.3<-c()
for (i in 1:length(ar011.3$coef)) { pvalores.ar011.3[i]<-wald.test(b = coef(ar011.3),
    Sigma = vcov(ar011.3), Terms =i)$result$chi2[3]}
pvalores.ar011.3

# Outliers
error.011.3<-residuals(ar011.3,type="response")
desv.tip<-sd(error.011.3) # Desviación típica del error
plot(error.011.3,main="Error de estimación ar.011.3")
abline(h=c(-3,-2,2,3)*desv.tip,lty=2,lwd=2,col=c("blue","red","red","blue"))
# valores atipicos, por encima de la 2.9 desviaciones típicas:
# error.011.3>2.9*desv.tip
# error.011.3< -2.9*desv.tip
```


Entonces, el modelo definitivo, partiendeo de lo que habíamos observado en ACF y PACF, es $log(y_t)$**~**$ARIMA_{12}(0,1,1)(0,1,1)$, con las intervenciones de junio y agosto de 2003, enero del 2005 y febrero del 2009.

#### Partiendo de ARIMA(1,1,0)(1,1,0)[12]  \newline

<!-- ```{r} -->
<!-- # ARIMA(1,1,0)(1,1,0)[12] -->
<!-- # estimación -->
<!-- ar110<-Arima(enf,order=c(1,1,0), -->
<!--               seasonal=list(order=c(1,1,0),period=12), -->
<!--               lambda=0, -->
<!--               xreg=cbind(bisiestos,d0803,d0105)) -->
<!-- ar110 -->

<!-- # Significatividad -->
<!-- pvalores.ar110<-c() -->
<!-- for (i in 1:length(ar110$coef)) pvalores.ar110[i]<-wald.test(b=coef(ar110),Sigma=vcov(ar110),Terms=i)$result$chi2[3] -->
<!-- pvalores.ar110 -->

<!-- # Outliers -->
<!-- error.110<-residuals(ar110,type="response") -->
<!-- desv.tip<-sd(error.110) # Desviación típica del error -->
<!-- plot(error.110,main="Error de estimación ar110") -->
<!-- abline(h=c(-3,-2,2,3)*desv.tip,lty=2,lwd=2,col=c("blue","red","red","blue")) -->
<!-- # valores atipicos, por encima de 2.9 desviaciones típicas: -->
<!-- error.110>2.9*desv.tip -->
<!-- error.110< -2.9*desv.tip -->
<!-- ``` -->


Por otro lado, al estimar un primer modelo del proceso $log(y_t)$**~**$ARIMA_{12}(1,1,0)(1,1,0)$ incluyendo como valores atípicos a tener en cuenta los febreros bisiestos, agosto de 2003 y enero de 2005, tenemos que tampoco es significativa la variable *bisiestos* que hemos creado, por lo que no la tenemos en cuenta al estimar un segundo modelo del mismo orden. Además, los posibles outliers corresponden a los febreros del 2000 y 2009 (cuyas variables *dummy* ya hemos creado previamente), así que los incorporamos en el nuevo modelo.

<!-- ```{r} -->
<!-- # ----------------- -->
<!-- # ARIMA(1,1,0)(1,1,0)[12] definitivo2 -->

<!-- # dummy's -->
<!-- ii <- order(abs(error.110), decreasing = TRUE) -->
<!-- d0200<-rep(0,length(error.110)) -->
<!-- d0209<-rep(0,length(error.110)) -->
<!-- d0209[ii[1]]<-1 # febrero del 2009 -->
<!-- d0200[ii[2]]<-1 # febrero del 2000 -->

<!-- # estimación -->
<!-- ar110.2<-Arima(enf,order=c(1,1,0), -->
<!--               seasonal=list(order=c(1,1,0),period=12), -->
<!--               lambda=0, -->
<!--               xreg=cbind(d0803,d0105,d0200,d0209)) -->
<!-- ar110.2 -->

<!-- # Significatividad -->
<!-- pvalores.ar110.2<-c() -->
<!-- for (i in 1:length(ar110.2$coef)) pvalores.ar110.2[i]<-wald.test(b=coef(ar110.2),Sigma=vcov(ar110.2),Terms=i)$result$chi2[3] -->
<!-- pvalores.ar110.2 -->

<!-- # Outliers -->
<!-- error.110.2<-residuals(ar110.2,type="response") -->
<!-- desv.tip<-sd(error.110.2) # Desviación típica del error -->
<!-- plot(error.110.2,main="Error de estimación ar110.2") -->
<!-- abline(h=c(-3,-2,2,3)*desv.tip,lty=2,lwd=2,col=c("blue","red","red","blue")) -->
<!-- # valores atipicos, por encima de 2.9 desviaciones típicas: -->
<!-- error.110.2>2.9*desv.tip -->
<!-- error.110.2< -2.9*desv.tip -->
<!-- ``` -->

Pero al estimarlo, tenemos que el coeficiente correspondiente a febrero del 2000 no es significativo, por lo que excluimos la variable correspondiente al estimar el tercer modelo. Además, ahora no tenemos ningún outlier.

<!-- ```{r} -->
<!-- # ----------------- -->
<!-- # ARIMA(1,1,0)(1,1,0)[12] -->

<!-- # estimación -->
<!-- ar110.3<-Arima(enf,order=c(1,1,0), -->
<!--               seasonal=list(order=c(1,1,0),period=12), -->
<!--               lambda=0, -->
<!--               xreg=cbind(d0803,d0105,d0209)) -->
<!-- ar110.3 -->

<!-- # Significatividad -->
<!-- pvalores.ar110.3<-c() -->
<!-- for (i in 1:length(ar110.3$coef)) pvalores.ar110.3[i]<-wald.test(b=coef(ar110.3),Sigma=vcov(ar110.3),Terms=i)$result$chi2[3] -->
<!-- pvalores.ar110.3 -->

<!-- # Outliers -->
<!-- error.110.3<-residuals(ar110.3,type="response") -->
<!-- desv.tip<-sd(error.110.3) # Desviación típica del error -->
<!-- plot(error.110.3,main="Error de estimación ar110.3") -->
<!-- abline(h=c(-3,-2,2,3)*desv.tip,lty=2,lwd=2,col=c("blue","red","red","blue")) -->
<!-- # valores atipicos, por encima de 2.9 desviaciones típicas: -->
<!-- error.110.3>2.9*desv.tip -->
<!-- error.110.3< -2.9*desv.tip -->
<!-- ``` -->

En el tercer modelo (ar110.3) ya tenemos todos los coeficientes significativos y que no se produce ningún error mayor a 2.9 desviaciones típicas (a excepción de febrero del 2000, que ya hemos visto que no es significativo).

Visualizamos a continuación el modelo estimado, los p-valores de cada uno de sus coeficientes y la gráfica del error del modelo (con bandas azules y rojas a 3 y 2 desviaciones típicas, respectivamente):

```{r mlpm , fig.width=13,fig.height=5}
# ARIMA(1,1,0)(1,1,0)[12]

# estimación
ar110.3<-Arima(enf,order=c(1,1,0),
              seasonal=list(order=c(1,1,0),period=12),
              lambda=0,
              xreg=cbind(d0803,d0105,d0209))
ar110.3

# Significatividad de cada uno de los coeficientes del modelo
pvalores.ar110.3<-c()
for (i in 1:length(ar110.3$coef)) { pvalores.ar110.3[i]<-wald.test(b=coef(ar110.3),
    Sigma=vcov(ar110.3),Terms=i)$result$chi2[3]}
pvalores.ar110.3

# Outliers
error.110.3<-residuals(ar110.3,type="response")
desv.tip<-sd(error.110.3) # Desviación típica del error
plot(error.110.3,main="Error de estimación ar110.3")
abline(h=c(-3,-2,2,3)*desv.tip,lty=2,lwd=2,col=c("blue","red","red","blue"))
# valores atipicos, por encima de 2.9 desviaciones típicas:
# error.110.3>2.9*desv.tip
# error.110.3< -2.9*desv.tip
```

El modelo definitivo partiendo de la propuesta de `auto.arima`, a falta de validarlo, sería entonces $log(y_t)$**~**$ARIMA_{12}(1,1,0)(1,1,0)$, con las intervenciones de agosto de 2003, enero de 2005 y febrero de 2009.

## Validación completa del modelo

Para que los modelos sean válidos han de cumplir una serie de consideraciones, como que todos los coeficientes del modelo sean significativos (que ya hemos estudiado previamente), u otras que giran en torno al concepto de que el residuo de los modelos hayan de ser ruido blanco. Estas consideraciones son: que la media sea 0; que sea homocedástico, incorrelado y que siga una distribución Normal. Las probamos con ambos modelos (estos son, *ar011.3* y *ar110.3*) teniendo en cuenta que la validación se realiza sobre el residuo original de los modelos, y vemos que el error en el modelo *ar110.3* es correlado (además de presentar mayor RMSE y MAPE que el de *ar011.3*). Entonces, consideramos que *ar011.3* es mejor modelo (de entre esos dos), pues sí supera todas las validaciones requeridas, las cuales mostramos a continuación:

 
#### Calidad de ajuste \newline

Podemos ver los valores de diferentes medidas de bondad de ajuste:

```{r}
accuracy(ar011.3)
```

No se puede contrastar si el residuo tiene media cero, pero el error medio es -0.878. Además, tenemos que el error porcentual medio (MAPE) es del 4.71%; un error cuadrático medio (RMSE) de 35.43; y que la predicción del intervalo de confianza es muy buena (ACF1 de 0.092, prácticamente 0).


#### Incorrelación \newline

Estudiamos la incorrelación con el test Box-Ljung, para el que en este caso la hipótesis nula es que $\rho_{1}=\rho_{2}=...=\rho_{k}=0$.

```{r}
Box.test(ar011.3$residuals,lag=2,type="Ljung-Box") # Parte regular
```

Realizamos la prueba para la parte regular estudiando si $\rho_{1}=\rho_{2}$, y obtenemos un p-valor de 0.4707, mayor al nivel de significatividad de 0.05, por lo que no
tenemos evidencia para rechazar la hipótesis nula y entonces aceptaremos que el residuo es incorrelado en la parte regular.

Para la parte estacional, nos interesaría saber si la autocorrelación en los retardos múltiplos al orden estacional ($\rho_{12}=\rho_{24}=\rho_{36}=\rho_{48}$...) son nulas, pero eso con el test Box-Ljung no lo podemos probar directamente. Aún así, cuando probamos si todas las autocorrelaciones hasta el 24º nivel de retardo son nulas, obtenemos un p-valor de 0.4542, por lo que no tenemos evidencia de que el residuo no sea incorrelado en la parte estacional.

```{r}
Box.test(ar011.3$residuals,lag=24,type="Ljung-Box") # Parte estacional
```

De todos modos, podemos visualizar la función de autocorrelación para observar directamente las autocorrelaciones en cada nivel de retardo, y vemos que efectivamente estas no son significativas (excepto en el 19º retardo, que no es relevante), por lo que podemos considerar que el error del modelo es incorrelado tanto en la parte regular como en la estacional.

```{r ssp, fig.width=13,fig.height=4}
ggAcf(ar011.3$residuals, lag=48)
```


#### Homocedasticidad \newline

Para estudiar la homocedasticidad, realizamos el mismo test Box-Ljung, pero para el cuadrado del residuo en lugar de para el residuo. En este caso, la hipótesis nula es que el residuo es homocedástico, esto es: $\rho_{1}(\epsilon^2_{t})=\rho_{2}(\epsilon^2_{t})=...=\rho_{k}(\epsilon^2_{t})=0$.

```{r}
Box.test(ar011.3$residuals^2, lag=2,type="Ljung-Box")
Box.test(ar011.3$residuals^2, lag=24,type="Ljung-Box")

```

Hemos obtenido que los p-valores para valores de k de 2 y 24 son, respectivamente, 0.44 y 0.2796, ambos mayores a 0.05, por lo que no tenemos evidencia para rechazar la hipótesis nula y entonces aceptaremos que el residuo es homocedástico tanto en la parte regular como en la estacional.

#### Normalidad \newline

Pese a que en este caso la condición de normalidad no es muy relevante debido a que se cumple el Teorema Central de Límite al disponer de una gran cantidad de datos, podemos estudiarla por ejemplo aplicando el test de Jarque-Bera sobre los residuos del modelo, cuya hipótesis nula es que se da normalidad.

```{r}
jarque.bera.test(ar011.3$residuals)
```

El p-valor es de 0.8132, mayor que 0.05, por lo que no tenemos evidencia para rechazar la hipótesis nula y entonces asumiremos que el residuo sigue una distribución Normal.

Con todo ello, el modelo *ar011.3* para la serie original de fallecimientos por enfermedades infecciosas y parasitarias ha pasado todas las validaciones requeridas.

#### Metodología Training Set/Test set: validación cruzada \newline

A continuación, validamos el modelo usando la metodología de *Training set/Test set*. Aplicamos entonces validación cruzada mediante el procedimiento llamado *origen de predicción móvil* (*rolling forecast origin*). Para ello, en este caso elegimos que el mínimo nº de meses para estimar sean 72 (es decir, 6 años), y un horizonte de predicciones de 24 meses. Se trata de un proceso iterativo en el que iremos desplazando las observaciones de la estimación un periodo adelante, e iremos calculando en este caso el MAPE para cada horizonte temporal.


```{r}
k <- 72  # Mínimo nº de datos para estimar
h <- 24  # Horizonte de las predicicones
T <- length(enf)  # Longitud de la serie
s <- T-k-h+1 # Total de estimaciones

mape.arima <- matrix(NA, s, h) 

X<-cbind(d0603,d0803,d0105,d0209)
for (i in 1:s) {
  train.set <- window(enf, start = 1998+(i-1)/12,  end = 1998+(k-2+i)/12)
  test.set  <- window(enf, start = 1998+(k-1+i)/12,end = 1998+(k+i+h-2)/12)  
  
  X.train<-X[i:(i+k-1),]
  hay<-colSums(X.train)
  X.train<-X.train[, hay>0]

  X.test<-X[(i+k):(i+k+h-1),]
  X.test<-X.test[,hay>0]
  
  if (length(X.train)>0){
    fit.ar<-Arima(train.set,
               order=c(0,1,1),
               seasonal=list(order=c(0,1,1),period=12),
               lambda=0,
               xreg=X.train)} else {
                 fit.ar<-Arima(train.set,
                            order=c(0,1,1),
                            seasonal=list(order=c(0,1,1),period=12),
                            lambda=0)
               }
  if (length(X.train)>0) fcast<-forecast(fit.ar,h=h,xreg=X.test) else
    fcast<-forecast(fit.ar,h=h)
  
  mape.arima[i,]<-100*abs(fcast$mean-test.set)/test.set
}

error.arima<-colMeans(mape.arima)
error.arima
```


El error extra-muestral a un periodo vista es aproximadamente de 5.71%, y va aumentando gradualmente según aumenta el horizonte de predicción, siendo el error a 24 periodos vista del 12.64%.

## Modelo definitivo

Entonces, el modelo definitivo que cumple toda la validación corresponde al proceso de las aerolíneas, y es el siguiente:

$log(y_t)$**~**$ARIMA_{12}(0,1,1)(0,1,1)+AI$, siendo las intervenciones los meses de junio y agosto de 2003, enero de 2005 y febrero de 2009. Esto es equivalente a $log(y_t)(1-L^{12})(1-L)=(1+\theta_1L)(1+\theta_{12}L^{12})\epsilon_t+AI$. Aplicando el operador retardo, teniendo en cuenta que $\Delta_{12}log(y_t)=TVAy_t$ (es decir, la tasa de variación anual) y desarrollando, tenemos que el modelo estimado es:

$\hat{TVAy_t}=TVAy_{t-1}+\theta_1\epsilon_{t-1}+\theta_{12}\epsilon_{t-12}+\theta_1\theta_{12}\epsilon_{t-13}+\gamma_1d0803+\gamma_2d0105+\gamma_3d0603+\gamma_4d0209$.

Si sustituimos los coeficientes por los que hemos obtenido en el modelo, tenemos que:

$\hat{TVAy_t}=TVAy_{t-1}-0.6286\epsilon_{t-1}-\epsilon_{t-12}+0.6286\epsilon_{t-13}+0.2484\cdot d0803+0.1334\cdot d0105+0.1520\cdot d0603-0.1067\cdot d0209$.

Es decir, la tasa de variación anual de los casos de fallecimientos por enfermedades infecciosas y parasitarias para un mes, es principalmente la misma que la del mes anterior, aunque si se observaron valores atípicos ese mes anterior o hace un año, ha de tenerse en cuenta para hacer la predicción; y también tenemos en cuanta algunos meses atípicos en los que la cantidad de fallecidos por este tipo de enfermedades en España fue distinta a la estimada. 

## Previsión de la serie

Mostramos a continuación la gráfica de la serie (en negro) con su previsión extra-muestral (en azul). Para ello, utilizamos todos los datos de los que disponemos para crear el modelo (es decir, utilizamos el modelo que hemos llamado *ar011.3*), y predecimos a un año vista con la función `forecast`.

```{r ssij, fig.width=13,fig.height=5}
hh<-12
(pred <- forecast(ar011.3, h = hh,
                     xreg = cbind( rep(0,hh), rep(0,hh), rep(0,hh),rep(0,hh)), 
                     level = 95)) 
plot(pred,PI=F)
```


## Valoración crítica del modelo ARIMA respecto de un modelo de alisado


En la práctica 2 vimos que la función `ets` proponía para nuestra serie un modelo con error multiplicativo, sin tendencia y con estacionalidad aditiva (M,N,A). En ese caso, obteníamos un MAPE de 5.16% y un RMSE de 38.77, tal como podemos ver a continuación.

```{r}
summary(ets(enf))
```


Sin embargo, ahora trabajamos sobre el logaritmo de la serie de enfermedades, y en este caso el método de alisado identifica un proceso (A,Ad,A), siendo $\alpha=0.4043$, $\beta=\gamma=0.0001\approx0$, y $\phi=0.9749$. Como el factor de amortiguamiento ($\phi$) es muy cercano a 1, le indicamos a la fución `ets` que no lo tenga en cuanta, de modo que ejecutando `ets(enf,lambda=0,damped=FALSE)` obtenemos que el método de alisado identifica un proceso (A,A,A) con $\alpha=0.4243$, $\beta=0.0003$ y $\gamma=0.0212$.
En este caso, el MAPE obtenido es también de aproximadamente 5.16%, y el RMSE de 38.64.

```{r}
summary(ets(enf,lambda=0,damped=FALSE))
```

Entonces, tenemos que tanto considerando el logaritmo como sin considerarlo, con el método de alisado obtenemos errores similares, y en ambos casos mayores a los obtenidos con ARIMA (que tal como ya hemos comentado en *Calidad del ajuste*, es un MAPE  del 4.71% y un RMSE de 35.43). Por tanto, con el modelo ARIMA esperamos obtener mejores resultados que con los de alisado, aunque también es cierto que no es una gran mejora y tal vez deberíamos plantearnos si merece la pena utilizar ARIMA, dada su mayor complejidad.

Como alternativa, podríamos comparar el modelo ARIMA respecto al de alisado aplicando también a este último la metodología *Training set/Test set*, de modo que podemos elegir el mismo nº mínimo de datos para estimar y mismo horizonte de predicciones que cuando hemos aplicado esta metodología con el modelo ARIMA (esto es, 6 años y 2 años respectivamente), y comparar los errores producidos con ambos métodos de predicción con respecto a los datos originales:

```{r}
# k <- 72  # Mínimo nº de datos para estimar
# h <- 24  # Horizonte de las predicicones
# T <- length(enf)  # Longitud  de la serie
# s <- T-k-h+1 # Total de estimaciones

mape.alisado <- matrix(NA, s, h) 
# ets(enf,lambda=0,damped=FALSE)

for (i in 1:s) {
  train.set <- window(enf, start = 1998+(i-1)/12,  end = 1998+(k-2+i)/12)
  test.set  <- window(enf, start = 1998+(k-1+i)/12,end = 1998+(k+i+h-2)/12)  
  
  fit.al <- ets(train.set, 
             model = "AAA", 
             damped=FALSE,
             lambda = 0) # estimamos el modelo de alisado
  fcast<-forecast(fit.al, h = h) # predecimos el modelo
  mape.alisado[i,] <- 100*abs(fcast$mean - test.set) / test.set
}

error.alisado <- colMeans(mape.alisado)
error.alisado

```

Representamos a continuación entonces el MAPE según el horizonte de previsión con el método de ARIMA (en verde) y con el de alisado (en rojo).

```{r plwodi, fig.width=13,fig.height=5}
plot(error.alisado,
     type = 'l',
     col = 'red',
     lwd = 2,
     lty = 2,
     xlab = 'Horizonte de previsión (meses)',
     ylab = '%',
     main = 'MAPE según el horizonte de previsión')

lines(error.arima,
      col = "green",
      lwd = 2,
      lty = 1)

legend("topleft",
      legend = c("ARIMA", "Alisado"),
      col = c("green", "red"),
      lwd = 2,
      lty = c(1, 2))
```


En el gráfico anterior podemos observar que el error extra-muestral a un periodo vista es un poco menor para alisado que para ARIMA, aunque muy parecido (MAPE de 5.58% frente a 5.71%), por lo que para hacer predicciones a corto plazo la precisión es similar con amobos. Sin embargo, para predicciones a más largo plazo (al menos hasta dos años que visualizamos en el gráfico), el error de predicción con ARIMA es inferior al de alisado, por lo que deducimos que sí predice mejor, aunque de nuevo vemos que esa mejora no es muy abrumada.






